# D-PlaneOS — NixOS Standalone Configuration
# ─────────────────────────────────────────────────────────────────────────────
# This file IS your entire NAS operating system configuration.
# Edit it, then run: sudo nixos-rebuild switch
#
# Hardware profile this file is tuned for:
#   Chassis:     SuperMicro SC721TQ-250B2
#   Motherboard: Gigabyte H610I DDR4 (Mini-ITX, LGA1700)
#   CPU:         Intel Core i3-13100 (Raptor Lake, 4C/8T, UHD 730)
#   RAM:         32 GB Crucial DDR4-3200 (2×16 GB dual-channel)
#   Boot drive:  Patriot P300 128 GB NVMe (DRAM-less, PCIe) → /dev/nvme0n1
#   Data drives: 2× WD 14 TB (WDC WD140EDFZ) + 2× Seagate 12 TB IronWolf Pro
#
# Recommended ZFS pool layout for the data drives:
#   Two mirrored VDEVs — maximises capacity, double redundancy:
#     VDEV 1:  mirror  WDC_WD140EDFZ_<serial1>  WDC_WD140EDFZ_<serial2>
#     VDEV 2:  mirror  ST12000NE0008_<serial1>   ST12000NE0008_<serial2>
#   Usable: ~23.6 TiB   Survives: any single disk failure per VDEV
#
#   Creation command (always use by-id paths, never /dev/sdX):
#     zpool create -o ashift=12 \
#       -O compression=lz4 -O xattr=sa -O acltype=posixacl -O atime=off \
#       tank \
#       mirror /dev/disk/by-id/ata-WDC_WD140EDFZ_<serial1> \
#              /dev/disk/by-id/ata-WDC_WD140EDFZ_<serial2> \
#       mirror /dev/disk/by-id/ata-ST12000NE0008_<serial1> \
#              /dev/disk/by-id/ata-ST12000NE0008_<serial2>
#
# Getting started: see INSTALLATION-GUIDE-NIXOS.md
# ─────────────────────────────────────────────────────────────────────────────

{ config, lib, pkgs, ... }:

{
  imports = [
    # Auto-generated hardware config — do NOT edit this file manually.
    # Regenerate with: nixos-generate-config --root /mnt
    ./hardware-configuration.nix

    # Auto-generated by D-PlaneOS daemon — do NOT edit by hand.
    # Contains NixOS-specific settings (firewall ports, Samba globals)
    # written by the web UI so they survive nixos-rebuild switch.
    # Network settings (IPs, VLANs, DNS) go directly to /etc/systemd/network/
    # — no nixos-rebuild needed for network changes.
    (if builtins.pathExists ./dplane-generated.nix
      then ./dplane-generated.nix
      else {})

    # D-PlaneOS Samba integration — declarative NixOS ownership of Samba,
    # with per-share config written by the web UI daemon.
    ./modules/samba.nix
  ];

  # ─── Allow D-PlaneOS (PolyForm Shield license) ──────────────────────────
  # NixOS classifies non-OSI-approved licenses as "unfree".
  # PolyForm Shield 1.0.0 is source-available but restricts commercial
  # competition — it is not OSI-approved, so this flag is required.
  # This only permits the D-PlaneOS daemon specifically.
  nixpkgs.config.allowUnfreePredicate = pkg:
    builtins.elem (lib.getName pkg) [
      "dplaneos-daemon"
    ];

  # ─── Boot loader ────────────────────────────────────────────────────────
  # H610I uses UEFI. systemd-boot is preferred over GRUB on appliances:
  # simpler, faster, and pairs well with the A/B OTA slot design in disko.nix.
  boot.loader.systemd-boot.enable      = true;
  boot.loader.efi.canTouchEfiVariables = true;

  # ─── Kernel ─────────────────────────────────────────────────────────────
  # Kernel pinned to 6.6 LTS in flake.nix via applianceConfig.
  # Raptor Lake is fully supported from 6.2+. 6.6 LTS is preferred over
  # linuxPackages_latest because the LTS series has verified OpenZFS compat.
  boot.initrd.availableKernelModules = [
    "nvme"     # Patriot P300 NVMe boot drive
    "ahci"     # SATA controller for WD/Seagate data drives
    "xhci_pci" # USB 3.x (H610I rear ports)
    "usbhid"   # USB HID (keyboard at install time)
    "sd_mod"   # SCSI disk layer (required by ahci)
  ];
  boot.kernelModules = [
    "kvm-intel" # Intel VT-x virtualisation support
  ];

  # Intel CPU microcode updates — applied at early boot from initrd.
  # Covers Raptor Lake errata and security mitigations.
  hardware.cpu.intel.updateMicrocode = true;

  # ─── Intel UHD Graphics 730 (i3-13100 integrated) ───────────────────────
  # Enables VA-API hardware video acceleration for media transcoding
  # in Docker containers (Jellyfin, Plex, Handbrake, etc.).
  # intel-media-driver (iHD) is correct for Gen 9–12 (Raptor Lake = Gen 12).
  # Do NOT add vaapiIntel — it is the legacy driver for pre-Gen9 hardware
  # and causes conflicts on Raptor Lake.
  hardware.graphics = {
    enable        = true;
    extraPackages = with pkgs; [
      intel-media-driver    # VA-API backend for UHD 730 (iHD driver, Gen 9–12)
      intel-compute-runtime # OpenCL support for compute workloads (optional)
    ];
  };

  # ─── ZFS ────────────────────────────────────────────────────────────────
  boot.supportedFilesystems = [ "zfs" ];

  # hostId MUST be unique per machine — ZFS uses it to prevent two systems
  # from importing the same pool simultaneously (data corruption risk).
  # Do NOT hardcode a shared value here.
  # setup-nixos.sh generates this from /etc/machine-id on first-boot setup.
  # Manual generation: head -c 8 /etc/machine-id
  networking.hostId = "00000000";  # ← setup-nixos.sh replaces this

  # ZFS ARC: cap at 16 GiB so Docker containers always have headroom.
  # 32 GB RAM − 16 GiB ARC − OS = comfortable margin for containers.
  boot.kernelParams = [ "zfs.zfs_arc_max=17179869184" ];

  services.zfs.autoScrub = {
    enable   = true;
    interval = "monthly";  # weekly unnecessary for home NAS write load
  };

  # Periodic TRIM for the NVMe boot drive.
  # DRAM-less drives benefit most from TRIM for wear levelling.
  services.zfs.trim.enable = true;

  # ─── Ensure /etc/systemd/network exists before the daemon starts ─────────
  # systemd-networkd creates /etc/systemd/network at runtime, but on NixOS
  # the directory may not yet exist when dplaned first tries to write a
  # 50-dplane-*.network file. This activation script pre-creates it so the
  # daemon never encounters a "directory not found" error on first network
  # change. ReadWritePaths for this directory is declared in module.nix.
  system.activationScripts.dplaneNetworkDir = {
    text = "mkdir -p /etc/systemd/network";
    deps = [];
  };

  # ─── Networking ─────────────────────────────────────────────────────────
  networking.hostName = "YOUR_HOSTNAME";  # !! REPLACE !!

  # Use systemd-networkd — required for D-PlaneOS network management.
  # D-PlaneOS writes /etc/systemd/network/50-dplane-*.{network,netdev} files
  # which survive reboots AND nixos-rebuild switch without any extra steps.
  # NixOS manages files with lower prefixes (10-, 20-); D-PlaneOS uses 50-.
  # They coexist — NixOS activation never touches files it did not create.
  networking.useDHCP     = false;
  networking.useNetworkd = true;
  systemd.network.enable = true;

  # Primary NIC: Realtek RTL8125B 2.5GbE on Gigabyte H610I.
  # Interface name on this board is typically enp2s0 (verify: ip link show).
  # D-PlaneOS takes over network management after first-boot setup; this
  # entry only provides initial DHCP connectivity to reach the web UI.
  systemd.network.networks."10-enp2s0" = {
    matchConfig.Name   = "enp2s0";
    networkConfig.DHCP = "yes";
  };

  # mDNS — allows access via http://YOUR_HOSTNAME.local on the local network.
  services.avahi = {
    enable   = true;
    nssmdns4 = true;
    publish  = {
      enable      = true;
      addresses   = true;
      workstation = true;
    };
  };

  # ─── Timezone & locale ──────────────────────────────────────────────────
  time.timeZone      = "Europe/Berlin";
  i18n.defaultLocale = "en_US.UTF-8";

  # ─── NVMe longevity — protect the Patriot P300 ──────────────────────────
  # The P300 is DRAM-less (SLC write cache → raw NAND). Minimising
  # unnecessary write amplification significantly extends drive life.
  # The NVMe carries only the OS, daemon binary, and SQLite DB — all
  # bulk data lives on the ZFS HDD pool.

  # Weekly TRIM — informs the NVMe FTL which blocks are free,
  # enabling more efficient wear levelling.
  services.fstrim = {
    enable   = true;
    interval = "weekly";
  };

  # ZRAM swap — compressed RAM swap instead of NVMe writes under pressure.
  # With 32 GB RAM this is almost never triggered; cheap safeguard.
  zramSwap = {
    enable        = true;
    memoryPercent = 10;   # ~3.2 GB ceiling
  };

  # Journal: bounded size + delayed fsync → fewer sequential NVMe writes.
  services.journald.extraConfig = ''
    Storage=persistent
    Compress=yes
    MaxRetentionSec=1month
    MaxFileSec=1day
    SyncIntervalSec=5m
    SystemMaxUse=512M
  '';

  # ─── CPU frequency governor ──────────────────────────────────────────────
  # powersave: the i3-13100 boosts to 4.5 GHz under load and idles at low
  # clock/voltage otherwise. In the SC721TQ-250B2 with its integrated 250 W
  # PSU, this keeps thermal headroom available for ZFS scrubs + transcoding.
  powerManagement.cpuFreqGovernor = "powersave";

  # ─── Docker ─────────────────────────────────────────────────────────────
  # storageDriver = overlay2: container layers stored on the NVMe at
  # /var/lib/docker using ext4 + overlayfs. Simpler and more reliable than
  # the ZFS storage driver, which would require Docker to manage ZFS datasets
  # directly — unnecessary when D-PlaneOS already manages the data pool.
  virtualisation.docker = {
    enable        = true;
    storageDriver = "overlay2";
    autoPrune.enable = true;
    # Container logs go to the system journal (bounded by 512 MB above)
    # instead of accumulating as JSON files on the NVMe boot drive.
    daemon.settings.log-driver = "journald";
  };

  # ─── Pangolin remote access — Newt tunnel client ────────────────────────
  # Newt establishes an outbound encrypted tunnel to the Pangolin VPS.
  # No inbound ports need to be opened on the router.
  #
  # Managed as a NixOS OCI container so systemd guarantees start order:
  # ZFS → dplaned → newt. The container is still visible in the D-PlaneOS
  # Docker dashboard (it IS a real Docker container).
  #
  # Correct image: fosrl/newt (https://github.com/fosrl/newt)
  # The Docker Hub organisation is "fosrl", not "pangolin".
  #
  # !! FILL IN your values from the Pangolin dashboard before deploying !!
  virtualisation.oci-containers = {
    backend = "docker";
    containers."newt" = {
      image     = "fosrl/newt:latest";
      autoStart = true;
      # host network: Newt needs to reach D-PlaneOS on 127.0.0.1:9000
      # and expose tunnelled services on the host network interfaces.
      extraOptions = [ "--network=host" "--restart=unless-stopped" ];
      environment = {
        PANGOLIN_ENDPOINT = "https://YOUR_PANGOLIN_DOMAIN";  # !! REPLACE !!
        NEWT_ID           = "YOUR_NEWT_ID";                  # !! REPLACE !!
        NEWT_SECRET       = "YOUR_NEWT_SECRET";              # !! REPLACE !!
      };
    };
  };

  # Start Newt only after D-PlaneOS daemon is up.
  # NixOS oci-containers does not have a native dependsOn option; use a
  # systemd service override instead (the container becomes docker-newt.service).
  systemd.services."docker-newt" = {
    after = [ "dplaned.service" ];
    wants = [ "dplaned.service" ];
  };

  # ─── D-PlaneOS service ──────────────────────────────────────────────────
  services.dplaneos = {
    enable       = true;
    openFirewall = true;
    # SSH public key for emergency headless access (password auth is disabled).
    # Example: [ "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAA... user@host" ]
    sshKeys = [
      "YOUR_SSH_PUBLIC_KEY"  # !! REPLACE !!
    ];
  };

  # ─── NTP ────────────────────────────────────────────────────────────────
  services.timesyncd.enable = true;

  # ─── Sysctl tuning for NAS workloads ────────────────────────────────────
  boot.kernel.sysctl = {
    # inotify — needed for file change monitoring across large media libraries
    "fs.inotify.max_user_watches"   = 524288;
    "fs.inotify.max_user_instances" = 512;
    "fs.inotify.max_queued_events"  = 32768;

    # VM — reduce swap pressure; favour file cache over anonymous pages
    "vm.swappiness"             = 10;
    "vm.vfs_cache_pressure"     = 50;
    "vm.dirty_background_ratio" = 5;
    "vm.dirty_ratio"            = 15;

    # TCP — improve throughput for SMB/NFS/rsync over 2.5 GbE
    "net.core.rmem_max"               = 134217728;
    "net.core.wmem_max"               = 134217728;
    "net.ipv4.tcp_rmem"               = "4096 87380 67108864";
    "net.ipv4.tcp_wmem"               = "4096 65536 67108864";
    "net.ipv4.tcp_congestion_control" = "bbr";
  };

  # ─── System packages ─────────────────────────────────────────────────────
  environment.systemPackages = with pkgs; [
    vim
    htop
    git
    wget
    curl
    lsof
    iotop
    zfs
    smartmontools   # disk health: smartctl -a /dev/sdX
    hdparm
    pciutils        # lspci
    usbutils        # lsusb
    nettools
    ethtool
    tcpdump
    nvme-cli        # NVMe health: nvme smart-log /dev/nvme0
    lm_sensors      # CPU/board temperature: sensors
  ];

  # ─── State version ───────────────────────────────────────────────────────
  # Do NOT change this after initial install. Controls NixOS migration logic.
  system.stateVersion = "25.11";
}
